{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import sys \n",
    "\n",
    "sys.path.insert(1, 'D:/IPS_PCA_CLUSTERING-the_end/')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "\n",
    "# custom\n",
    "from src.utils.dataset import RSSIDataset\n",
    "from src.utils.file_utils import read_data, load_data, load_csv\n",
    "from src.utils.helper import get_current_date, normalize_data, separates_data_uts, mean_error, clip_gradient, \\\n",
    "    constant_columns, detect_num_feature_rssi, load_data_npz, draw_distribution_cluster, draw_kmean_distortion, \\\n",
    "    draw_kmean_silhouette, set_seed_everything\n",
    "from src.utils.models import RegressionNet, ClassificationNet, Ensemble_Model, Ensemble_Classic_Model, train_regression, \\\n",
    "    train_classification, model_evaluation, classic_model_evaluation, load_model_classification, save_model_sklearn, \\\n",
    "    load_model_sklearn\n",
    "from src.utils.loss import MeanLoss\n",
    "import src.utils.regr_utils as regr\n",
    "\n",
    "SEED = 2023\n",
    "set_seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str = get_current_date()\n",
    "# date_str = \"2023_02_05\"\n",
    "n_cluster_str = 2\n",
    "idx_data_type = 0\n",
    "data_type_str = [\"uts\", \"uji\", \"tampere\"]\n",
    "detail_data = \"kernal_pca_cosine_250\"\n",
    "\n",
    "all_path = {\n",
    "    'type': 'kernel_pca_250 | Tampere | 2_cluster_label',\n",
    "    'n_clusters': 2,\n",
    "    'result_path': f'../../results/floor_classification/{data_type_str[idx_data_type]}/{detail_data}.csv',\n",
    "    'data_dir': f\"../../data/{data_type_str[idx_data_type]}_data/pca/{detail_data}/\",\n",
    "    'cluster': f'../../models/{data_type_str[idx_data_type]}_models/cluster_{n_cluster_str}/{date_str}/model_cluster.sav',\n",
    "    'cluster_classifier': f'../../models/{data_type_str[idx_data_type]}_models/cluster_{n_cluster_str}/{date_str}/model_cluster_classifier.sav',\n",
    "    'ensemble_classifier': f'../../models/{data_type_str[idx_data_type]}_models/cluster_{n_cluster_str}/{date_str}/ensemble_classifier',\n",
    "    'floor_classifier': f'../../models/{data_type_str[idx_data_type]}_models/cluster_{n_cluster_str}/{date_str}/model_floor_classifier.sav',\n",
    "}\n",
    "Path(all_path[\"ensemble_classifier\"]).mkdir(parents=True, exist_ok=True)\n",
    "Path(f'../../models/{data_type_str[idx_data_type]}_models/cluster_{n_cluster_str}/{date_str}/').mkdir(parents=True, exist_ok=True)\n",
    "data_type_str[idx_data_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = \"../../data/uts_data/pca/kernal_pca_cosine_100/\"\n",
    "data_dir = all_path[\"data_dir\"]\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test), (X_valid, Y_valid) = load_data_npz(\n",
    "    [\n",
    "        os.path.join(data_dir, \"X_train.npz\"),\n",
    "        os.path.join(data_dir, \"Y_train.npz\"),\n",
    "        os.path.join(data_dir, \"X_test.npz\"),\n",
    "        os.path.join(data_dir, \"Y_test.npz\"),\n",
    "        os.path.join(data_dir, \"X_valid.npz\"),\n",
    "        os.path.join(data_dir, \"Y_valid.npz\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# cluster_model = load_model_sklearn(all_path[\"cluster\"])\n",
    "# Z_train = cluster_model.predict(Y_train[:,:2])\n",
    "# Z_test = cluster_model.predict(Y_test[:,:2])\n",
    "# Z_valid = cluster_model.predict(Y_valid[:,:2])\n",
    "\n",
    "X_train = np.vstack([X_train, X_valid])\n",
    "Y_train = np.vstack([Y_train, Y_valid])\n",
    "\n",
    "Y_train = Y_train[:, 2]\n",
    "Y_test = Y_test[:, 2]\n",
    "Y_valid = Y_valid[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************** tampere | kernal_pca_cosine_75 ************** \n",
      "KNeighborsClassifier()\n",
      "\tScore: 0.8663629460895975 | Training Time: 0.11192536354064941\n",
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9334345735256897 | Training Time: 0.030046939849853516\n",
      "SGDClassifier()\n",
      "\tScore: 0.9336876740065806 | Training Time: 0.010107755661010742\n",
      "DecisionTreeClassifier(max_depth=5, random_state=2023)\n",
      "\tScore: 0.7727157681599595 | Training Time: 0.016002178192138672\n",
      "RandomForestClassifier(max_depth=5, random_state=2023)\n",
      "\tScore: 0.8790179701341433 | Training Time: 0.1901721954345703\n",
      "SVC(C=0.025, kernel='linear', random_state=2023)\n",
      "\tScore: 0.3844596304732979 | Training Time: 0.06834006309509277\n",
      "SVC(C=1, gamma=2, random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9291318653505442 | Training Time: 0.1441340446472168\n",
      "SVC(probability=True, random_state=2023)\n",
      "\tScore: 0.9334345735256897 | Training Time: 0.19291186332702637\n",
      "MLPClassifier(random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9445709946848899 | Training Time: 0.6022012233734131\n",
      "GaussianNB()\n",
      "\tScore: 0.856238926853961 | Training Time: 0.012152671813964844\n",
      "LinearDiscriminantAnalysis()\n",
      "\tScore: 0.938243482662617 | Training Time: 0.04021930694580078\n",
      "QuadraticDiscriminantAnalysis()\n",
      "\tScore: 0.8678815489749431 | Training Time: 0.0238187313079834\n",
      "AdaBoostClassifier(random_state=2023)\n",
      "\tScore: 0.5069602632245002 | Training Time: 0.2459864616394043\n",
      "GradientBoostingClassifier(learning_rate=1.0, max_depth=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9212857504429258 | Training Time: 3.30130934715271\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=2023, ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9319159706403443 | Training Time: 0.23749041557312012\n",
      "\n",
      "************** uji | kernal_pca_cosine_100 ************** \n",
      "KNeighborsClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.8811881188118812 | Training Time: 0.5403566360473633\n",
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9054905490549054 | Training Time: 1.0742154121398926\n",
      "SGDClassifier()\n",
      "\tScore: 0.918091809180918 | Training Time: 0.1839299201965332\n",
      "DecisionTreeClassifier(max_depth=5, random_state=2023)\n",
      "\tScore: 0.6291629162916291 | Training Time: 0.9188938140869141\n",
      "RandomForestClassifier(max_depth=5, random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.7875787578757876 | Training Time: 6.5794970989227295\n",
      "SVC(C=0.025, kernel='linear', random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.882988298829883 | Training Time: 13.970324754714966\n",
      "SVC(C=1, gamma=2, random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9198919891989199 | Training Time: 4.4782609939575195\n",
      "SVC(probability=True, random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9270927092709271 | Training Time: 14.875645875930786\n",
      "MLPClassifier(random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9198919891989199 | Training Time: 19.135172605514526\n",
      "GaussianNB()\n",
      "\tScore: 0.5229522952295229 | Training Time: 0.04300498962402344\n",
      "LinearDiscriminantAnalysis()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9045904590459046 | Training Time: 0.2095966339111328\n",
      "QuadraticDiscriminantAnalysis()\n",
      "\tScore: 0.846984698469847 | Training Time: 0.13094234466552734\n",
      "AdaBoostClassifier(random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.1998199819981998 | Training Time: 13.008460521697998\n",
      "GradientBoostingClassifier(learning_rate=1.0, max_depth=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.8874887488748875 | Training Time: 546.8872413635254\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              objective='multi:softprob', predictor=None, ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9081908190819082 | Training Time: 14.036362886428833\n",
      "\n",
      "************** uts | kernal_pca_cosine_250 ************** \n",
      "KNeighborsClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9432989690721649 | Training Time: 0.10938668251037598\n",
      "LogisticRegression()\n",
      "\tScore: 0.9484536082474226 | Training Time: 0.7512407302856445\n",
      "SGDClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9407216494845361 | Training Time: 0.4560821056365967\n",
      "DecisionTreeClassifier(max_depth=5, random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.7216494845360825 | Training Time: 0.6389338970184326\n",
      "RandomForestClassifier(max_depth=5, random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.8865979381443299 | Training Time: 4.069830894470215\n",
      "SVC(C=0.025, kernel='linear', random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9072164948453608 | Training Time: 5.163082122802734\n",
      "SVC(C=1, gamma=2, random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9639175257731959 | Training Time: 1.872197151184082\n",
      "SVC(probability=True, random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9561855670103093 | Training Time: 7.700740814208984\n",
      "MLPClassifier(random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9355670103092784 | Training Time: 5.7417027950286865\n",
      "GaussianNB()\n",
      "\tScore: 0.8917525773195877 | Training Time: 0.04865765571594238\n",
      "LinearDiscriminantAnalysis()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9407216494845361 | Training Time: 0.34966349601745605\n",
      "QuadraticDiscriminantAnalysis()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.595360824742268 | Training Time: 0.386981725692749\n",
      "AdaBoostClassifier(random_state=2023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.14948453608247422 | Training Time: 9.00521993637085\n",
      "GradientBoostingClassifier(learning_rate=1.0, max_depth=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.8402061855670103 | Training Time: 166.59912657737732\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              objective='multi:softprob', predictor=None, ...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScore: 0.9355670103092784 | Training Time: 6.9796435832977295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IPS_PCA_CLUSTERING-the_end\\src\\utils\\helper.py:228: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log = log.append(log_entry, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import src.utils.cls_utils as clf\n",
    "from src.utils.helper import get_result_floor_classifier\n",
    "\n",
    "data_type = [\"tampere\", \"uji\", \"uts\"]\n",
    "\n",
    "for data_prefix in data_type:\n",
    "    for sub_folder in os.listdir(f\"../../data/{data_prefix}_data/pca/\"):\n",
    "        # if sub_folder == \"no_pca\":\n",
    "        #     continue\n",
    "        print(f\"************** {data_prefix} | {sub_folder} ************** \")\n",
    "        data_dir = f\"../../data/{data_prefix}_data/pca/{sub_folder}/\"\n",
    "\n",
    "        (X_train, Y_train), (X_test, Y_test), (X_valid, Y_valid) = load_data_npz(\n",
    "            [\n",
    "                os.path.join(data_dir, \"X_train.npz\"),\n",
    "                os.path.join(data_dir, \"Y_train.npz\"),\n",
    "                os.path.join(data_dir, \"X_test.npz\"),\n",
    "                os.path.join(data_dir, \"Y_test.npz\"),\n",
    "                os.path.join(data_dir, \"X_valid.npz\"),\n",
    "                os.path.join(data_dir, \"Y_valid.npz\")\n",
    "            ]\n",
    "        )\n",
    "        X_train = np.vstack([X_train, X_valid])\n",
    "        Y_train = np.vstack([Y_train, Y_valid])\n",
    "\n",
    "        Y_train = Y_train[:, 2]\n",
    "        Y_test = Y_test[:, 2]\n",
    "\n",
    "        get_result_floor_classifier(\n",
    "            clf.models_trial,\n",
    "            X_train, Y_train,\n",
    "            X_test, Y_test,\n",
    "            data_prefix,\n",
    "            f\"../../results/floor_classification/{data_prefix}/{sub_folder}.csv\"\n",
    "        )\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_result_floor_classifier(\u001b[43mmodel_list\u001b[49m, X_train, Y_train, X_test, Y_test,\n\u001b[0;32m      2\u001b[0m                             data_type\u001b[38;5;241m=\u001b[39mdata_type_str[idx_data_type],\n\u001b[0;32m      3\u001b[0m                             result_path\u001b[38;5;241m=\u001b[39mall_path[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult_path\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_list' is not defined"
     ]
    }
   ],
   "source": [
    "get_result_floor_classifier(model_list, X_train, Y_train, X_test, Y_test,\n",
    "                            data_type=data_type_str[idx_data_type],\n",
    "                            result_path=all_path[\"result_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train floor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ = X_train[Z_train == 0]\n",
    "# Y_train_ = Y_train[Z_train == 0]\n",
    "#\n",
    "# X_valid_ = X_valid[Z_valid == 0]\n",
    "# Y_valid_ = Y_valid[Z_valid == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = LogisticRegression()\n",
    "# m.fit(X_train_, Y_train_)\n",
    "# m.score(X_valid_, Y_valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.utils.cls_utils as clf\n",
    "# en_model = clf.Ensemble_Classic_Model(\n",
    "#     models= [\n",
    "#         SGDClassifier(),\n",
    "#         MLPClassifier(), LogisticRegression(),\n",
    "#         SVC(kernel='rbf', probability=True),\n",
    "#         XGBClassifier(), RandomForestClassifier(),\n",
    "#         KNeighborsClassifier()\n",
    "#     ],\n",
    "#     ensemble_model_path=all_path[\"ensemble_classifier\"]\n",
    "# )\n",
    "# en_model.train_student(X_train, Y_train, Z_train, X_valid, Y_valid, Z_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.classic_model_evaluation(\n",
    "#     model_dict_path=[\n",
    "#         os.path.join(all_path[\"ensemble_classifier\"], \"model_0.sav\"),\n",
    "#         os.path.join(all_path[\"ensemble_classifier\"], \"model_1.sav\"),\n",
    "#         # os.path.join(all_path[\"ensemble_classifier\"], \"model_2.sav\"),\n",
    "#     ],\n",
    "#     model_cluster_classifier_path=all_path[\"cluster_classifier\"],\n",
    "#     X_test=X_test,\n",
    "#     Y_test=Y_test\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train base 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf1 = MLPClassifier()\n",
    "# clf2 = LogisticRegression()\n",
    "# clf3 = SVC(kernel='rbf', probability=True)\n",
    "# clf4 = XGBClassifier()\n",
    "# clf5 = GaussianNB()\n",
    "# clf6 = SGDClassifier()\n",
    "# clf7 = KNeighborsClassifier()\n",
    "# clf8 = DecisionTreeClassifier()\n",
    "# clf9 = RandomForestClassifier()\n",
    "# clf10 = GradientBoostingClassifier()\n",
    "#\n",
    "# eclf = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('clf1', clf1), ('clf2', clf2), ('clf3', clf3)\n",
    "#     ],\n",
    "#     voting=\"soft\",\n",
    "#     weights=[3, 1, 2]\n",
    "# )\n",
    "#\n",
    "# model_list = [clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf8, clf9, clf10, eclf]\n",
    "#\n",
    "# print(f\"Train clf1 model: {clf1.__class__.__name__}\")\n",
    "# clf1 = clf1.fit(X_train, Y_train)\n",
    "# print(clf1.score(X_test, Y_test))\n",
    "#\n",
    "# print(f\"Train clf2 model: {clf2.__class__.__name__}\")\n",
    "# clf2 = clf2.fit(X_train, Y_train)\n",
    "# print(clf2.score(X_test, Y_test))\n",
    "#\n",
    "# print(f\"Train clf3 model: {clf3.__class__.__name__}\")\n",
    "# clf3 = clf3.fit(X_train, Y_train)\n",
    "# print(clf3.score(X_test, Y_test))\n",
    "#\n",
    "# print(f\"Train clf3 model: {clf4.__class__.__name__}\")\n",
    "# clf4 = clf4.fit(X_train, Y_train)\n",
    "# print(clf4.score(X_test, Y_test))\n",
    "#\n",
    "# print(f\"Train eclf model: {eclf.__class__.__name__}\")\n",
    "# eclf = eclf.fit(X_train, Y_train)\n",
    "# print(eclf.score(X_test, Y_test))\n",
    "#\n",
    "# save_model_sklearn(all_path[\"floor_classifier\"], eclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = load_model_sklearn(all_path[\"floor_classifier\"])\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(\"\\nFinal\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_0\n",
      "[[-0.32710986  0.26471843  0.2284243  ... -0.01962228  0.01599412\n",
      "  -0.02166901]\n",
      " [-0.0887591   0.00370714 -0.01304901 ... -0.00221932 -0.00737536\n",
      "  -0.00360871]\n",
      " [ 0.09886772  0.32281415 -0.1254653  ... -0.01247815 -0.00067846\n",
      "  -0.02028829]\n",
      " ...\n",
      " [-0.30898421  0.11282028  0.29537248 ...  0.00162467 -0.03156896\n",
      "   0.02052481]\n",
      " [ 0.1238168  -0.14711911 -0.20325805 ...  0.02832593 -0.00089344\n",
      "  -0.02201901]\n",
      " [-0.11102505 -0.13316179 -0.15960501 ... -0.03597616  0.01809136\n",
      "  -0.00819005]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
